{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"collapsed":true},"source":["# BL40A2010 Introduction to IoT-Based Systems\n","\n","## Assignment 6, 27.02.2023\n","\n","### Author: Semen Kovesnikov"]},{"cell_type":"markdown","metadata":{},"source":["**Prisoner's dilemma** is a standard example of a game analyzed in game theory that shows why two completely rational individuals might not cooperate, even if it appears that it is in their best interests to do so. It was originally framed by Merrill Flood and Melvin Dresher while working at RAND in 1950. Albert W. Tucker formalized the game with prison sentence rewards and named it \"prisoner's dilemma\", presenting it as follows:\n","\n","\"Two members of a criminal gang are arrested and imprisoned. Each prisoner is in solitary confinement with no means of communicating with the other. The prosecutors lack sufficient evidence to convict the pair on the principal charge, but they have enough to convict both on a lesser charge. Simultaneously, the prosecutors offer each prisoner a bargain. Each prisoner is given the opportunity either to betray the other by testifying that the other committed the crime, or to cooperate with the other by remaining silent. The possible outcomes are:\n","\n","- If A and B each betray the other (not-cooperating to each other), each of them serves $z$ years in prison (payoff of $-z$)\n","- If A betrays B (not-cooperating with B) but B remains silent (cooperating with A), A will serve $y$ years in prison (payoff $-y$) and B will serve $w$ years  (payoff of $-w$).\n","- If B betrays A (not-cooperating with A) but A remains silent (cooperating with B), B will serve $y$ years in prison (payoff $-y$) and A will serve $w$ years  (payoff of $-w$).\n","- If A and B both remain silent, both of them will serve $x$ years in prison (payoff of $-x$).\"\n","\n","The payoff table is presented below. \n","\n","|                | $B$ cooperates  | $B$ not-cooperating   |\n","|----------------|:---------------:|--------------:|\n","| $A$ cooperates |  $A \\rightarrow -x$   | $A\\rightarrow -w$  |\n","|                |  $B\\rightarrow -x$   | $B\\rightarrow -y$  |\n","|                |                 |               |\n","| $A$ not-cooperating   |  $A\\rightarrow -y$   | $A\\rightarrow -z$  |\n","|                |  $B\\rightarrow -w$   | $B\\rightarrow -z$  |\n","\n","**However, this is only a *Prisoner's Dilemma GAME* for A GIVEN RELATION between the years in prison (payoffs) as to be studied next.**\n","\n","ps. Text adapted from [Wikipedia](https://en.wikipedia.org/wiki/Prisoner's_dilemma)."]},{"cell_type":"markdown","metadata":{},"source":["**(1) Consider the Prisoner's dilemma description given above.**\n","\n","**(a) What is the relation between the payoffs values $x\\geq 0$, $y\\geq 0$, $w\\geq 0$ and $z \\geq 0$ so that the game can be classified as [Prisoner's Dilemma](https://en.wikipedia.org/wiki/Prisoner's_dilemma)?**\n","\n","**(b) Verify the results (i.e., the proposed inequality) with numerical examples using [nashpy](https://nashpy.readthedocs.io/en/stable/index.html). Please provide one example when the inequality holds and one it does not (check my example for Dove and Hawyk game).**"]},{"cell_type":"code","execution_count":1,"metadata":{"trusted":false},"outputs":[],"source":["#lib import\n","import numpy as np\n","import nashpy as nash"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["If neither A nor B confess, then they will both bear less amount of years, than if they both defect, and more if only one confesses. Hence, $y<x<z$.\n","However, if one betrays another, and the second one stays silent, then the silent one gets more years than in case of both silent. Thus, $z<w$.\n","This gives us\n","\n","$y<x<z<w$"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["Bi matrix game with payoff matrices:\n","\n","Row player:\n","[[-3 -5]\n"," [-2 -4]]\n","\n","Column player:\n","[[-3 -2]\n"," [-5 -4]]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["A=[[-3, -5],[-2, -4]]\n","B=[[-3, -2],[-5, -4]]\n","prisonners_dilemma=nash.Game(A,B)\n","prisonners_dilemma"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["[(array([0., 1.]), array([0., 1.]))]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["eq=prisonners_dilemma.support_enumeration()\n","list(eq)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["From the result, it can be seen that they will not cooperate."]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["[(array([1., 0.]), array([1., 0.])),\n"," (array([0., 1.]), array([0., 1.])),\n"," (array([0.66666667, 0.33333333]), array([0.66666667, 0.33333333]))]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["A=[[0, -5],[-1, -3]]\n","B=[[0, -1],[-5, -3]]\n","prisonners_dilemma=nash.Game(A,B)\n","eq=prisonners_dilemma.support_enumeration()\n","list(eq)"]},{"cell_type":"markdown","metadata":{},"source":["**(2) Justify why the game from the previous exercise is or is not a good (reasonable) model when $A$ and $B$ are:**\n","\n","**1. Two trained members from the army when they are in prison.**\n","\n","\n","**2. Competitive companies in the market discussing standardization.**\n","\n","\n","**3. Two different autonomous IoT-based home energy management algorithms that are focus on energy efficiency.**\n","\n","\n","**4. Two different autonomous IoT-based home energy management algorithms that are focus on profit maximization.**\n","\n","**ps. You need to think about the assumption used in Game Theory and in the Prisoner's dilemma problem setting.**"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Answer:\n","1. The model isn't representative, as it's likely that trained members will cooperate, knowing the best outcome, because they are used to behave as a group, and not like an individual.\n","2. Here it depends. It may be that it's much more profitable to push your own standard, so that others have to adopt it. However, if a completely new standard needed, then a cooperation is more appealing, as the spendings on development can be shared between companies. Otherwise the CAPEX may be too high. Of course, the revenue will be split as well, but it's still some profit.\n","3. Not really, as energy efficiency of one algorithm isn't connected to an other, then it's not the case of Prisonners dilemma.\n","4. When it comes to profit maximixation, each algorithm will be working for its own benifit, hence they will be in rival. But it's much better for them to cooperate to reach the common goal. The type of source also matters, as it can be the same or not for the algorithms."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"2ae7915851d74fe7399be5c49df080b19a7eb83a7316f9cd1f14531a53bd1ff3"}}},"nbformat":4,"nbformat_minor":2}
